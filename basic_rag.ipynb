{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3940d85c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import weaviate\n",
    "\n",
    "client = weaviate.connect_to_local()\n",
    "\n",
    "print(client.is_ready())  # Should print: `True`\n",
    "\n",
    "client.close()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c42ab3e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/moraish/Desktop/ams691/project_llm/.venv/lib/python3.9/site-packages/weaviate/collections/classes/config.py:1950: PydanticDeprecatedSince211: Accessing the 'model_fields' attribute on the instance is deprecated. Instead, you should access this attribute from the model class. Deprecated in Pydantic V2.11 to be removed in V3.0.\n",
      "  for cls_field in self.model_fields:\n"
     ]
    }
   ],
   "source": [
    "import weaviate\n",
    "from weaviate.classes.config import Configure\n",
    "\n",
    "client = weaviate.connect_to_local()\n",
    "\n",
    "questions = client.collections.create(\n",
    "    name=\"Question\",\n",
    "    vectorizer_config=Configure.Vectorizer.text2vec_ollama(     # Configure the Ollama embedding integration\n",
    "        api_endpoint=\"http://host.docker.internal:11434\",       # Allow Weaviate from within a Docker container to contact your Ollama instance\n",
    "        model=\"nomic-embed-text\",                               # The model to use\n",
    "    ),\n",
    "    generative_config=Configure.Generative.ollama(              # Configure the Ollama generative integration\n",
    "        api_endpoint=\"http://host.docker.internal:11434\",       # Allow Weaviate from within a Docker container to contact your Ollama instance\n",
    "        model=\"llama3.2\",                                       # The model to use\n",
    "    )\n",
    ")\n",
    "\n",
    "client.close()  # Free up resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f412cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate\n",
    "import requests, json\n",
    "\n",
    "client = weaviate.connect_to_local()\n",
    "\n",
    "resp = requests.get(\n",
    "    \"https://raw.githubusercontent.com/weaviate-tutorials/quickstart/main/data/jeopardy_tiny.json\"\n",
    ")\n",
    "data = json.loads(resp.text)\n",
    "\n",
    "questions = client.collections.get(\"Question\")\n",
    "\n",
    "with questions.batch.rate_limit(requests_per_minute=200) as batch:\n",
    "    for d in data:\n",
    "        batch.add_object(\n",
    "            {\n",
    "                \"answer\": d[\"Answer\"],\n",
    "                \"question\": d[\"Question\"],\n",
    "                \"category\": d[\"Category\"],\n",
    "            }\n",
    "        )\n",
    "        if batch.number_errors > 10:\n",
    "            print(\"Batch import stopped due to excessive errors.\")\n",
    "            break\n",
    "\n",
    "failed_objects = questions.batch.failed_objects\n",
    "if failed_objects:\n",
    "    print(f\"Number of failed imports: {len(failed_objects)}\")\n",
    "    print(f\"First failed object: {failed_objects[0]}\")\n",
    "\n",
    "client.close()  # Free up resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e54e084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"answer\": \"Sound barrier\",\n",
      "  \"question\": \"In 70-degree air, a plane traveling at about 1,130 feet per second breaks it\",\n",
      "  \"category\": \"SCIENCE\"\n",
      "}\n",
      "{\n",
      "  \"answer\": \"the atmosphere\",\n",
      "  \"question\": \"Changes in the tropospheric layer of this are what gives us weather\",\n",
      "  \"category\": \"SCIENCE\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import weaviate\n",
    "import json\n",
    "\n",
    "client = weaviate.connect_to_local()\n",
    "\n",
    "questions = client.collections.get(\"Question\")\n",
    "\n",
    "response = questions.query.near_text(\n",
    "    query=\"air\",\n",
    "    limit=2\n",
    ")\n",
    "\n",
    "for obj in response.objects:\n",
    "    print(json.dumps(obj.properties, indent=2))\n",
    "\n",
    "client.close()  # Free up resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c51317d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Did you know? ü§îüß¨ DNA is the molecule that holds our genes! üí° And, did you know that the liver üëç plays a crucial role in regulating blood sugar levels by removing excess glucose and storing it as glycogen? üîÑüí™ Mind. Blown. #ScienceFacts #DNA #Liver\"\n"
     ]
    }
   ],
   "source": [
    "import weaviate\n",
    "\n",
    "client = weaviate.connect_to_local()\n",
    "\n",
    "questions = client.collections.get(\"Question\")\n",
    "\n",
    "response = questions.generate.near_text(\n",
    "    query=\"biology\",\n",
    "    limit=2,\n",
    "    grouped_task=\"Write a tweet with emojis about these facts.\"\n",
    ")\n",
    "\n",
    "print(response.generated)  # Inspect the generated text\n",
    "\n",
    "client.close()  # Free up resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15d84b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"invertedIndexConfig\": {\n",
      "        \"bm25\": {\n",
      "            \"b\": 0.75,\n",
      "            \"k1\": 1.2\n",
      "        },\n",
      "        \"cleanupIntervalSeconds\": 60,\n",
      "        \"indexNullState\": false,\n",
      "        \"indexPropertyLength\": false,\n",
      "        \"indexTimestamps\": false,\n",
      "        \"stopwords\": {\n",
      "            \"preset\": \"en\"\n",
      "        }\n",
      "    },\n",
      "    \"multiTenancyConfig\": {\n",
      "        \"enabled\": false,\n",
      "        \"autoTenantCreation\": false,\n",
      "        \"autoTenantActivation\": false\n",
      "    },\n",
      "    \"properties\": [\n",
      "        {\n",
      "            \"name\": \"category\",\n",
      "            \"description\": \"This property was generated by Weaviate's auto-schema feature on Thu Apr 24 01:42:36 2025\",\n",
      "            \"dataType\": [\n",
      "                \"text\"\n",
      "            ],\n",
      "            \"indexFilterable\": true,\n",
      "            \"indexSearchable\": true,\n",
      "            \"indexRangeFilters\": false,\n",
      "            \"tokenization\": \"word\",\n",
      "            \"moduleConfig\": {\n",
      "                \"text2vec-ollama\": {\n",
      "                    \"skip\": false,\n",
      "                    \"vectorizePropertyName\": false\n",
      "                }\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"question\",\n",
      "            \"description\": \"This property was generated by Weaviate's auto-schema feature on Thu Apr 24 01:42:36 2025\",\n",
      "            \"dataType\": [\n",
      "                \"text\"\n",
      "            ],\n",
      "            \"indexFilterable\": true,\n",
      "            \"indexSearchable\": true,\n",
      "            \"indexRangeFilters\": false,\n",
      "            \"tokenization\": \"word\",\n",
      "            \"moduleConfig\": {\n",
      "                \"text2vec-ollama\": {\n",
      "                    \"skip\": false,\n",
      "                    \"vectorizePropertyName\": false\n",
      "                }\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"answer\",\n",
      "            \"description\": \"This property was generated by Weaviate's auto-schema feature on Thu Apr 24 01:42:36 2025\",\n",
      "            \"dataType\": [\n",
      "                \"text\"\n",
      "            ],\n",
      "            \"indexFilterable\": true,\n",
      "            \"indexSearchable\": true,\n",
      "            \"indexRangeFilters\": false,\n",
      "            \"tokenization\": \"word\",\n",
      "            \"moduleConfig\": {\n",
      "                \"text2vec-ollama\": {\n",
      "                    \"skip\": false,\n",
      "                    \"vectorizePropertyName\": false\n",
      "                }\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"replicationConfig\": {\n",
      "        \"factor\": 1,\n",
      "        \"asyncEnabled\": false,\n",
      "        \"deletionStrategy\": \"NoAutomatedResolution\"\n",
      "    },\n",
      "    \"shardingConfig\": {\n",
      "        \"virtualPerPhysical\": 128,\n",
      "        \"desiredCount\": 1,\n",
      "        \"actualCount\": 1,\n",
      "        \"desiredVirtualCount\": 128,\n",
      "        \"actualVirtualCount\": 128,\n",
      "        \"key\": \"_id\",\n",
      "        \"strategy\": \"hash\",\n",
      "        \"function\": \"murmur3\"\n",
      "    },\n",
      "    \"vectorIndexConfig\": {\n",
      "        \"cleanupIntervalSeconds\": 300,\n",
      "        \"distanceMetric\": \"cosine\",\n",
      "        \"dynamicEfMin\": 100,\n",
      "        \"dynamicEfMax\": 500,\n",
      "        \"dynamicEfFactor\": 8,\n",
      "        \"ef\": -1,\n",
      "        \"efConstruction\": 128,\n",
      "        \"filterStrategy\": \"sweeping\",\n",
      "        \"flatSearchCutoff\": 40000,\n",
      "        \"maxConnections\": 32,\n",
      "        \"skip\": false,\n",
      "        \"vectorCacheMaxObjects\": 1000000000000\n",
      "    },\n",
      "    \"vectorIndexType\": \"hnsw\",\n",
      "    \"vectorizer\": \"text2vec-ollama\",\n",
      "    \"class\": \"Question\",\n",
      "    \"moduleConfig\": {\n",
      "        \"generative-ollama\": {\n",
      "            \"apiEndpoint\": \"http://host.docker.internal:11434\",\n",
      "            \"model\": \"llama3.2\"\n",
      "        },\n",
      "        \"text2vec-ollama\": {\n",
      "            \"apiEndpoint\": \"http://host.docker.internal:11434\",\n",
      "            \"model\": \"nomic-embed-text\",\n",
      "            \"vectorizeClassName\": true\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "\n",
    "# 1. View Scheam for a collection\n",
    "\n",
    "import weaviate\n",
    "import json\n",
    "\n",
    "client = weaviate.connect_to_local()\n",
    "questions = client.collections.get(\"Question\")\n",
    "config = questions.config.get()\n",
    "\n",
    "print(json.dumps(config.to_dict(), indent=4))\n",
    "\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b2a344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QueryReturn(objects=[])\n"
     ]
    }
   ],
   "source": [
    "import weaviate, json\n",
    "\n",
    "client = weaviate.connect_to_local()\n",
    "papers = client.collections.get(\"ResearchPapers\")\n",
    "\n",
    "response = papers.query.near_text(\n",
    "    query=\"atlas\",\n",
    "    limit=2,\n",
    "    return_metadata=[\"distance\"],      # optional extras\n",
    "    return_properties=[\"paper_title\", \"chunk_text\"]\n",
    ")\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9cacb5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QueryReturn(objects=[])\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b88fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "papers = client.collections.get('ResearchPapers')\n",
    "vector_names = ['paper_title', 'chunk_text']\n",
    "\n",
    "data_object = papers.query.fetch_object_by_id(\n",
    "    uuid=obj_uuid,  # Object UUID\n",
    "    include_vector=vector_names  # Specify names of the vectors to include\n",
    ")\n",
    "\n",
    "# The vectors are returned in the `vector` property as a dictionary\n",
    "for n in vector_names:\n",
    "    print(f\"Vector '{n}': {data_object.vector[n][:5]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06fc1fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ResearchPapers': _CollectionConfig(name='ResearchPapers', description=None, generative_config=_GenerativeConfig(generative=<GenerativeSearches.OLLAMA: 'generative-ollama'>, model={'apiEndpoint': 'http://host.docker.internal:11434', 'model': 'llama3'}), inverted_index_config=_InvertedIndexConfig(bm25=_BM25Config(b=0.75, k1=1.2), cleanup_interval_seconds=60, index_null_state=False, index_property_length=False, index_timestamps=False, stopwords=_StopwordsConfig(preset=<StopwordsPreset.EN: 'en'>, additions=None, removals=None)), multi_tenancy_config=_MultiTenancyConfig(enabled=False, auto_tenant_creation=False, auto_tenant_activation=False), properties=[_Property(name='chunk_text', description='The text content of the paper chunk', data_type=<DataType.TEXT: 'text'>, index_filterable=True, index_range_filters=False, index_searchable=True, nested_properties=None, tokenization=<Tokenization.WORD: 'word'>, vectorizer_config=_PropertyVectorizerConfig(skip=False, vectorize_property_name=False), vectorizer='text2vec-ollama', vectorizer_configs=None), _Property(name='paper_title', description='Title of the research paper', data_type=<DataType.TEXT: 'text'>, index_filterable=True, index_range_filters=False, index_searchable=True, nested_properties=None, tokenization=<Tokenization.FIELD: 'field'>, vectorizer_config=_PropertyVectorizerConfig(skip=True, vectorize_property_name=True), vectorizer='text2vec-ollama', vectorizer_configs=None), _Property(name='source', description='Source filename of the PDF', data_type=<DataType.TEXT: 'text'>, index_filterable=True, index_range_filters=False, index_searchable=True, nested_properties=None, tokenization=<Tokenization.FIELD: 'field'>, vectorizer_config=_PropertyVectorizerConfig(skip=True, vectorize_property_name=True), vectorizer='text2vec-ollama', vectorizer_configs=None), _Property(name='page', description='Page number of the chunk', data_type=<DataType.INT: 'int'>, index_filterable=True, index_range_filters=False, index_searchable=False, nested_properties=None, tokenization=None, vectorizer_config=_PropertyVectorizerConfig(skip=True, vectorize_property_name=True), vectorizer='text2vec-ollama', vectorizer_configs=None), _Property(name='chunk_id', description='Unique ID for the chunk within the document', data_type=<DataType.TEXT: 'text'>, index_filterable=True, index_range_filters=False, index_searchable=True, nested_properties=None, tokenization=<Tokenization.FIELD: 'field'>, vectorizer_config=_PropertyVectorizerConfig(skip=True, vectorize_property_name=True), vectorizer='text2vec-ollama', vectorizer_configs=None), _Property(name='start_index', description='Start index of the chunk in the original document', data_type=<DataType.INT: 'int'>, index_filterable=True, index_range_filters=False, index_searchable=False, nested_properties=None, tokenization=None, vectorizer_config=_PropertyVectorizerConfig(skip=True, vectorize_property_name=True), vectorizer='text2vec-ollama', vectorizer_configs=None)], references=[], replication_config=_ReplicationConfig(factor=1, async_enabled=False, deletion_strategy=<ReplicationDeletionStrategy.NO_AUTOMATED_RESOLUTION: 'NoAutomatedResolution'>), reranker_config=None, sharding_config=_ShardingConfig(virtual_per_physical=128, desired_count=1, actual_count=1, desired_virtual_count=128, actual_virtual_count=128, key='_id', strategy='hash', function='murmur3'), vector_index_config=_VectorIndexConfigHNSW(multi_vector=None, quantizer=None, cleanup_interval_seconds=300, distance_metric=<VectorDistances.COSINE: 'cosine'>, dynamic_ef_min=100, dynamic_ef_max=500, dynamic_ef_factor=8, ef=-1, ef_construction=128, filter_strategy=<VectorFilterStrategy.SWEEPING: 'sweeping'>, flat_search_cutoff=40000, max_connections=32, skip=False, vector_cache_max_objects=1000000000000), vector_index_type=<VectorIndexType.HNSW: 'hnsw'>, vectorizer_config=_VectorizerConfig(vectorizer=<Vectorizers.TEXT2VEC_OLLAMA: 'text2vec-ollama'>, model={'apiEndpoint': 'http://host.docker.internal:11434', 'model': 'nomic-embed-text'}, vectorize_collection_name=True), vectorizer=<Vectorizers.TEXT2VEC_OLLAMA: 'text2vec-ollama'>, vector_config=None), 'Question': _CollectionConfig(name='Question', description=None, generative_config=_GenerativeConfig(generative=<GenerativeSearches.OLLAMA: 'generative-ollama'>, model={'apiEndpoint': 'http://host.docker.internal:11434', 'model': 'llama3.2'}), inverted_index_config=_InvertedIndexConfig(bm25=_BM25Config(b=0.75, k1=1.2), cleanup_interval_seconds=60, index_null_state=False, index_property_length=False, index_timestamps=False, stopwords=_StopwordsConfig(preset=<StopwordsPreset.EN: 'en'>, additions=None, removals=None)), multi_tenancy_config=_MultiTenancyConfig(enabled=False, auto_tenant_creation=False, auto_tenant_activation=False), properties=[_Property(name='category', description=\"This property was generated by Weaviate's auto-schema feature on Thu Apr 24 01:42:36 2025\", data_type=<DataType.TEXT: 'text'>, index_filterable=True, index_range_filters=False, index_searchable=True, nested_properties=None, tokenization=<Tokenization.WORD: 'word'>, vectorizer_config=_PropertyVectorizerConfig(skip=False, vectorize_property_name=False), vectorizer='text2vec-ollama', vectorizer_configs=None), _Property(name='question', description=\"This property was generated by Weaviate's auto-schema feature on Thu Apr 24 01:42:36 2025\", data_type=<DataType.TEXT: 'text'>, index_filterable=True, index_range_filters=False, index_searchable=True, nested_properties=None, tokenization=<Tokenization.WORD: 'word'>, vectorizer_config=_PropertyVectorizerConfig(skip=False, vectorize_property_name=False), vectorizer='text2vec-ollama', vectorizer_configs=None), _Property(name='answer', description=\"This property was generated by Weaviate's auto-schema feature on Thu Apr 24 01:42:36 2025\", data_type=<DataType.TEXT: 'text'>, index_filterable=True, index_range_filters=False, index_searchable=True, nested_properties=None, tokenization=<Tokenization.WORD: 'word'>, vectorizer_config=_PropertyVectorizerConfig(skip=False, vectorize_property_name=False), vectorizer='text2vec-ollama', vectorizer_configs=None)], references=[], replication_config=_ReplicationConfig(factor=1, async_enabled=False, deletion_strategy=<ReplicationDeletionStrategy.NO_AUTOMATED_RESOLUTION: 'NoAutomatedResolution'>), reranker_config=None, sharding_config=_ShardingConfig(virtual_per_physical=128, desired_count=1, actual_count=1, desired_virtual_count=128, actual_virtual_count=128, key='_id', strategy='hash', function='murmur3'), vector_index_config=_VectorIndexConfigHNSW(multi_vector=None, quantizer=None, cleanup_interval_seconds=300, distance_metric=<VectorDistances.COSINE: 'cosine'>, dynamic_ef_min=100, dynamic_ef_max=500, dynamic_ef_factor=8, ef=-1, ef_construction=128, filter_strategy=<VectorFilterStrategy.SWEEPING: 'sweeping'>, flat_search_cutoff=40000, max_connections=32, skip=False, vector_cache_max_objects=1000000000000), vector_index_type=<VectorIndexType.HNSW: 'hnsw'>, vectorizer_config=_VectorizerConfig(vectorizer=<Vectorizers.TEXT2VEC_OLLAMA: 'text2vec-ollama'>, model={'apiEndpoint': 'http://host.docker.internal:11434', 'model': 'nomic-embed-text'}, vectorize_collection_name=True), vectorizer=<Vectorizers.TEXT2VEC_OLLAMA: 'text2vec-ollama'>, vector_config=None)}\n"
     ]
    }
   ],
   "source": [
    "response = client.collections.list_all(simple=False)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c68eb86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
